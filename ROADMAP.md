# ğŸ¯ Master's Thesis Roadmap: Lightweight Sign Language Recognition

**Project:** Lightweight Real-Time Sign Language Recognition on Edge Devices
**Student:** Kgomotso Larry Sebela
**Repository:** https://github.com/MafasaBytes/silver-sniffle
**Target:** >85% accuracy, 30+ FPS, <100MB model, 8GB VRAM

---

## ğŸ“Š Project Status Dashboard

**Current Phase:** Phase I - Baseline Development
**Current Week:** Week 1 - Feature Extraction
**Overall Progress:** 15% Complete

### âœ… Completed Milestones
- [x] Research proposal finalized
- [x] Dataset downloaded (RWTH-PHOENIX-Weather 2014 SI5)
- [x] Development environment setup
- [x] YOLOv8 + MediaPipe feature extraction pipeline implemented
- [x] Windows compatibility issues resolved (tqdm, MediaPipe warnings)
- [x] Repository initialized on GitHub
- [x] Branch renamed to `main`
- [x] Code cleanup: Archived experimental scripts
- [x] Architecture decision: 177 features (body + hands, no face)

### â³ In Progress
- [ ] Feature extraction: Train split (60/4,376 samples = 1.4%)
- [ ] BiLSTM model architecture design

### â­ï¸ Next Up (This Week)
- [ ] Complete train split extraction (~18 hours GPU time)
- [ ] Extract dev split (106 samples, ~30 min)
- [ ] Extract test split (175 samples, ~45 min)
- [ ] Verify extracted features shape and quality

### ğŸ“… Upcoming (Next 2 Weeks)
- [ ] Implement BiLSTM + CTC model
- [ ] Train baseline model
- [ ] Evaluate WER on test set

---

## ğŸ—ºï¸ Three-Phase Development Plan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE I: Baseline Development (Weeks 1-4) â³ IN PROGRESS   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Goal: Establish baseline performance with handcrafted       â”‚
â”‚       features + BiLSTM architecture                         â”‚
â”‚ Target WER: 35-45% (comparable to Koller et al. 2015)      â”‚
â”‚ Status: Feature extraction started                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE II: Architecture Optimization (Weeks 5-8) ğŸ“… PLANNED â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Goal: Replace handcrafted features with end-to-end learning â”‚
â”‚       using MobileNetV3 + knowledge distillation             â”‚
â”‚ Target WER: <25% (thesis requirement)                       â”‚
â”‚ Status: Not started                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE III: Real-time Deployment (Weeks 9-10) ğŸ“… PLANNED    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Goal: Optimize for 30+ FPS inference with TensorRT          â”‚
â”‚ Target: <100MB model, real-time browser deployment          â”‚
â”‚ Status: Not started                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“… Phase I: Baseline Development (Weeks 1-4)

### Week 1: Feature Extraction â³ IN PROGRESS

**Objective:** Extract spatial-temporal features from all dataset splits

**Tasks:**
- [x] Set up extraction pipeline (`extract_features_yolov8_gpu.py`)
- [ ] Extract train split (4,376 sequences)
  - Status: 60/4,376 complete (1.4%)
  - Estimated time: 16-18 hours GPU
  - Command: `python src/extract_features_yolov8_gpu.py --split train --batch-size 8`
- [ ] Extract dev split (106 sequences, ~30 min)
  - Command: `python src/extract_features_yolov8_gpu.py --split dev --batch-size 8`
- [ ] Extract test split (175 sequences, ~45 min)
  - Command: `python src/extract_features_yolov8_gpu.py --split test --batch-size 8`
- [ ] Verify feature quality (spot-check 10 samples)
- [ ] Document extraction metrics (FPS, GPU usage, failures)

**Outputs:**
- `data/processed/train/*.npy` (4,376 files, ~1.5GB)
- `data/processed/dev/*.npy` (106 files, ~40MB)
- `data/processed/test/*.npy` (175 files, ~65MB)
- `extraction_metrics_yolov8.csv` (performance logs)
- `extraction_summary_yolov8.json` (statistics)

**Success Criteria:**
- [ ] All 4,657 sequences extracted successfully
- [ ] Feature shape: (num_frames, 177) for each sequence
- [ ] <1% extraction failures
- [ ] Extraction logs show consistent ~7-8 FPS

**GPU Schedule:**
```
Start: Monday 8:00 AM
â”œâ”€â”€ Train extraction: ~18 hours â†’ Tuesday 2:00 AM
â”œâ”€â”€ Dev extraction: ~30 min â†’ Tuesday 2:30 AM
â””â”€â”€ Test extraction: ~45 min â†’ Tuesday 3:15 AM
Complete: Tuesday morning
```

---

### Week 2: BiLSTM Model Implementation

**Objective:** Build and train baseline sequence-to-sequence model

**Tasks:**
- [ ] Create `src/train_bilstm.py`
- [ ] Implement data loader for .npy features
- [ ] Design BiLSTM architecture:
  ```
  Input: (batch, seq_len, 177)
  â”œâ”€â”€ BiLSTM Layer 1: 256 hidden units
  â”œâ”€â”€ Dropout: 0.3
  â”œâ”€â”€ BiLSTM Layer 2: 256 hidden units
  â”œâ”€â”€ Dropout: 0.3
  â”œâ”€â”€ Linear projection: 256 â†’ vocab_size
  â””â”€â”€ CTC Loss
  ```
- [ ] Implement CTC loss function
- [ ] Set up training loop with checkpointing
- [ ] Configure TensorBoard logging
- [ ] Implement early stopping (patience=5 epochs)
- [ ] Start training (estimated 2-3 days GPU time)

**Hyperparameters:**
```python
batch_size = 16
learning_rate = 1e-3
optimizer = AdamW
scheduler = ReduceLROnPlateau(patience=3)
max_epochs = 50
gradient_clip = 5.0
```

**Outputs:**
- `models/bilstm_baseline_epoch{N}.pth`
- `logs/bilstm_baseline/` (TensorBoard logs)
- `training_metrics.csv`

**Success Criteria:**
- [ ] Training loss converges (< 50 after 20 epochs)
- [ ] Validation WER shows improvement
- [ ] No NaN losses or gradient explosions
- [ ] Model checkpoints saved every 5 epochs

---

### Week 3: Baseline Evaluation & Analysis

**Objective:** Measure baseline performance and identify improvement areas

**Tasks:**
- [ ] Create `src/evaluate.py` for WER calculation
- [ ] Implement CTC beam search decoder
- [ ] Evaluate on test set:
  - Word Error Rate (WER)
  - Sign Error Rate (SER)
  - Inference time per sequence
  - Memory usage
- [ ] Compare with Koller et al. (2015) baseline (~40% WER)
- [ ] Analyze error patterns:
  - Confusion matrix for common signs
  - Sequence length vs error rate
  - Temporal boundary errors
- [ ] Create visualizations:
  - Training/validation curves
  - Attention weights (if applicable)
  - Sample predictions vs ground truth

**Outputs:**
- `results/phase1_baseline_results.json`
- `results/error_analysis.csv`
- `results/confusion_matrix.png`
- `results/sample_predictions.txt`

**Success Criteria:**
- [ ] Test WER: 35-45% (within expected baseline range)
- [ ] Inference speed: >10 FPS (batched processing)
- [ ] Results documented in thesis draft (Chapter V)

---

### Week 4: Phase I Documentation & Transition

**Objective:** Document Phase I results and prepare for Phase II

**Tasks:**
- [ ] Write Phase I technical report:
  - Feature extraction methodology
  - BiLSTM architecture details
  - Training procedures
  - Evaluation results
  - Lessons learned
- [ ] Create ablation study plan for Phase II
- [ ] Document architectural decisions:
  - Why 177 features instead of 543?
  - Why skip facial features?
  - Impact on accuracy vs speed
- [ ] Update thesis Chapter IV (Methodology)
- [ ] Update thesis Chapter V (Experimental Results - Phase I)
- [ ] Git commit: "Complete Phase I baseline implementation"
- [ ] Archive Phase I models and logs

**Outputs:**
- `docs/phase1_report.md`
- `docs/phase1_ablation_plan.md`
- Thesis draft updates

**Checkpoint Review:**
- [ ] Phase I objectives achieved?
- [ ] Baseline WER acceptable?
- [ ] Ready to proceed to Phase II?
- [ ] Any blockers for Phase II?

---

## ğŸ“… Phase II: Architecture Optimization (Weeks 5-8)

### Week 5: MobileNetV3 Integration

**Objective:** Replace handcrafted features with end-to-end learned features

**Tasks:**
- [ ] Create `src/train_mobilenet.py`
- [ ] Implement MobileNetV3 backbone (pretrained on ImageNet)
- [ ] Design spatial-temporal fusion architecture:
  ```
  Video Frames (210x260x3)
    â†“
  MobileNetV3-Small (feature extractor)
    â†“
  Temporal Pooling / Conv3D
    â†“
  BiLSTM (sequence modeling)
    â†“
  CTC Loss
  ```
- [ ] Implement data augmentation:
  - Random rotation (Â±10Â°)
  - Random scaling (0.9-1.1)
  - Color jitter
  - Temporal jittering
- [ ] Set up mixed-precision training (FP16)
- [ ] Implement gradient checkpointing

**Architecture Specifications:**
```python
# MobileNetV3-Small configuration
input_size = (210, 260, 3)
backbone_output = 576  # features before classifier
temporal_fusion = "average"  # or "lstm"
bilstm_hidden = 256
num_layers = 2
```

**Success Criteria:**
- [ ] Model fits in 8GB VRAM
- [ ] Training starts without OOM errors
- [ ] Convergence observed within 10 epochs

---

### Week 6: Knowledge Distillation

**Objective:** Transfer knowledge from larger teacher models

**Tasks:**
- [ ] Download pre-trained teacher model (I3D or SlowFast)
- [ ] Implement distillation loss:
  ```python
  L_total = 0.7 * L_soft + 0.3 * L_hard
  L_soft = KL_divergence(student_logits/T, teacher_logits/T)
  L_hard = CTC_loss(student_logits, ground_truth)
  T = 3.0  # temperature
  ```
- [ ] Generate soft targets from teacher model
- [ ] Train student model with distillation
- [ ] Monitor student vs teacher performance gap

**Hyperparameters:**
```python
temperature = 3.0
alpha = 0.7  # soft loss weight
beta = 0.3   # hard loss weight
learning_rate = 5e-4  # lower for distillation
```

**Success Criteria:**
- [ ] Student achieves 95% of teacher accuracy
- [ ] Model size <100MB (thesis requirement)
- [ ] 90% parameter reduction vs teacher

---

### Week 7: Optimization & Ablation Studies

**Objective:** Fine-tune architecture and validate design choices

**Tasks:**
- [ ] Run ablation studies:
  - **A:** Baseline vs proposed architecture
  - **B:** With/without knowledge distillation
  - **C:** Temporal window sizes (16, 32, 64 frames)
  - **D:** Impact of attention mechanisms
  - **E:** Different optimization techniques
- [ ] Hyperparameter tuning:
  - Learning rate sweep
  - Batch size optimization
  - Dropout rates
  - Weight decay
- [ ] Implement selective attention mechanism (if beneficial)
- [ ] Cross-validation on training set (5-fold)

**Outputs:**
- `results/ablation_study_results.csv`
- `results/hyperparameter_tuning.json`
- Statistical significance tests

**Success Criteria:**
- [ ] Test WER: <25% (thesis requirement âœ…)
- [ ] Ablation studies show component contributions
- [ ] Results documented with mean Â± std dev

---

### Week 8: Phase II Evaluation & Documentation

**Objective:** Validate Phase II results and prepare for deployment

**Tasks:**
- [ ] Final evaluation on test set
- [ ] Calculate all target metrics:
  - WER, SER, BLEU scores
  - Inference FPS (batch mode)
  - Memory footprint
  - Model size
- [ ] Compare with state-of-the-art:
  - Koller et al. (2015)
  - Recent RWTH-PHOENIX benchmarks
- [ ] Statistical significance testing
- [ ] Update thesis chapters:
  - Chapter IV: Architecture details
  - Chapter V: Phase II results
  - Chapter VII: Discussion
- [ ] Prepare model for Phase III deployment
- [ ] Git tag: `v1.0-phase2-complete`

**Outputs:**
- `results/phase2_final_results.json`
- `models/mobilenet_optimized_final.pth`
- Thesis draft (80% complete)

**Checkpoint Review:**
- [ ] WER <25%? âœ…
- [ ] Model size <100MB? âœ…
- [ ] Ready for real-time optimization?

---

## ğŸ“… Phase III: Real-time Deployment (Weeks 9-10)

### Week 9: TensorRT Optimization

**Objective:** Achieve 30+ FPS real-time inference

**Tasks:**
- [ ] Convert PyTorch model to ONNX format
- [ ] Optimize ONNX model (constant folding, operator fusion)
- [ ] Convert ONNX to TensorRT engine
- [ ] Implement sliding window processing:
  ```python
  window_size = 32  # frames
  stride = 8        # frames
  buffer = RingBuffer(capacity=32)
  ```
- [ ] Create `src/inference.py` for real-time processing
- [ ] Benchmark inference latency:
  - Single frame: <30ms
  - Full sequence: report RTF (Real-Time Factor)
- [ ] Measure end-to-end latency (camera â†’ prediction)

**Performance Targets:**
```
Inference FPS: 30+ (thesis requirement)
Latency: <100ms end-to-end
Memory: <2GB GPU usage
```

**Success Criteria:**
- [ ] Achieves 30+ FPS âœ…
- [ ] TensorRT engine 2-3x faster than PyTorch
- [ ] Predictions match PyTorch model (Â±0.1% WER)

---

### Week 10: User Study & Thesis Finalization

**Objective:** Validate system with real users and complete thesis

**Tasks:**
- [ ] Implement browser deployment (TensorFlow.js)
- [ ] Create simple web interface for sign language translation
- [ ] Recruit 5-10 deaf/hard-of-hearing participants
- [ ] Conduct user study:
  - System Usability Scale (SUS) questionnaire
  - Task completion rates
  - Qualitative feedback interviews
- [ ] Analyze user study results
- [ ] Finalize all thesis chapters:
  - Chapter I: Introduction âœ“
  - Chapter II: Literature Review âœ“
  - Chapter III: Theoretical Framework âœ“
  - Chapter IV: Methodology âœ“
  - Chapter V: Experimental Results âœ“
  - Chapter VI: User Study â† New
  - Chapter VII: Discussion âœ“
  - Chapter VIII: Conclusion âœ“
- [ ] Proofread and format thesis
- [ ] Prepare presentation slides
- [ ] Submit thesis

**Outputs:**
- `deployment/web_demo/` (TensorFlow.js app)
- `results/user_study_results.csv`
- **Final thesis PDF** âœ…

**Success Criteria:**
- [ ] SUS score >70 (acceptable usability)
- [ ] Thesis submitted on time
- [ ] All research objectives achieved

---

## ğŸ—ï¸ Technical Architecture

### Current Pipeline (Phase I)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAINING PIPELINE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Raw Video Frames (210x260px PNG)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Extraction (extract_features_yolov8_gpu.py)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ YOLOv8-Pose (GPU): 17 keypoints â†’ 51 features            â”‚
â”‚  â€¢ MediaPipe Hands (CPU): 42 landmarks â†’ 126 features        â”‚
â”‚  â€¢ Total: 177 features per frame                             â”‚
â”‚  â€¢ Performance: ~7.5 FPS on RTX 4070                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
Feature Files (.npy)
  Shape: (num_frames, 177)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BiLSTM Model (train_bilstm.py)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: (batch, seq_len, 177)                                â”‚
â”‚  â”œâ”€â”€ BiLSTM Layer 1: 256 hidden                              â”‚
â”‚  â”œâ”€â”€ BiLSTM Layer 2: 256 hidden                              â”‚
â”‚  â”œâ”€â”€ Linear: 256 â†’ vocab_size                                â”‚
â”‚  â””â”€â”€ CTC Loss                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
Predictions (text)
```

### Future Pipeline (Phase II)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                END-TO-END PIPELINE (Phase II)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Raw Video Frames (210x260px)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MobileNetV3 Feature Extractor (GPU)                         â”‚
â”‚  â€¢ Learns features end-to-end                                â”‚
â”‚  â€¢ No separate feature extraction step                       â”‚
â”‚  â€¢ 30+ FPS inference (TensorRT optimized)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
Learned Features
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BiLSTM Sequence Model                                        â”‚
â”‚  â€¢ Temporal modeling                                          â”‚
â”‚  â€¢ CTC alignment                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
Predictions (text)
```

---

## ğŸ“‚ Repository Structure

```
sign-language-recognition/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data/
â”‚   â”‚   â””â”€â”€ phoenix-2014-signerindependent-SI5/
â”‚   â”‚       â”œâ”€â”€ features/fullFrame-210x260px/
â”‚   â”‚       â”‚   â”œâ”€â”€ train/  (4,376 video folders)
â”‚   â”‚       â”‚   â”œâ”€â”€ dev/    (106 video folders)
â”‚   â”‚       â”‚   â””â”€â”€ test/   (175 video folders)
â”‚   â”‚       â””â”€â”€ annotations/manual/
â”‚   â”‚           â”œâ”€â”€ train.SI5.corpus.csv
â”‚   â”‚           â”œâ”€â”€ dev.SI5.corpus.csv
â”‚   â”‚           â””â”€â”€ test.SI5.corpus.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train/  (4,376 .npy files) â³ IN PROGRESS
â”‚       â”œâ”€â”€ dev/    (106 .npy files) ğŸ“… PENDING
â”‚       â”œâ”€â”€ test/   (175 .npy files) ğŸ“… PENDING
â”‚       â””â”€â”€ logs/   (extraction logs)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract_features_yolov8_gpu.py  âœ… PRODUCTION
â”‚   â”œâ”€â”€ train_bilstm.py                  ğŸ“… Week 2
â”‚   â”œâ”€â”€ train_mobilenet.py               ğŸ“… Week 5
â”‚   â”œâ”€â”€ evaluate.py                      ğŸ“… Week 3
â”‚   â”œâ”€â”€ inference.py                     ğŸ“… Week 9
â”‚   â”œâ”€â”€ dataset_explorer.py              âœ… Utility
â”‚   â”œâ”€â”€ gpu_pose_test.py                 âœ… Testing
â”‚   â”œâ”€â”€ phoenix_dataset.py               âœ… Data loader
â”‚   â”œâ”€â”€ archive/                         ğŸ“¦ Old experiments
â”‚   â”‚   â”œâ”€â”€ mediapipe_feature_extractor.py
â”‚   â”‚   â”œâ”€â”€ extract_full_dataset.py
â”‚   â”‚   â””â”€â”€ ... (deprecated scripts)
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ctc_decoder.py               ğŸ“… Week 2
â”‚       â”œâ”€â”€ metrics.py                   ğŸ“… Week 3
â”‚       â””â”€â”€ visualization.py             ğŸ“… Week 3
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ bilstm_baseline_*.pth            ğŸ“… Week 2-3
â”‚   â”œâ”€â”€ mobilenet_optimized_*.pth        ğŸ“… Week 6-7
â”‚   â””â”€â”€ tensorrt_engines/                ğŸ“… Week 9
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ tensorboard/
â”‚   â”‚   â”œâ”€â”€ bilstm_baseline/
â”‚   â”‚   â””â”€â”€ mobilenet_optimized/
â”‚   â””â”€â”€ training_logs/
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ phase1_baseline_results.json
â”‚   â”œâ”€â”€ phase2_final_results.json
â”‚   â”œâ”€â”€ ablation_study_results.csv
â”‚   â””â”€â”€ user_study_results.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_analysis.ipynb
â”‚   â””â”€â”€ 03_error_analysis.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ phase1_report.md
â”‚   â”œâ”€â”€ phase2_report.md
â”‚   â””â”€â”€ api_documentation.md
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ tensorrt/
â”‚   â””â”€â”€ web_demo/
â”‚
â”œâ”€â”€ .gitignore                           âœ…
â”œâ”€â”€ requirements.txt                     âœ…
â”œâ”€â”€ CLAUDE.md                            âœ… AI assistant guide
â”œâ”€â”€ ROADMAP.md                           âœ… This file
â”œâ”€â”€ README.md                            ğŸ“… Update weekly
â””â”€â”€ research-proposal.md                 âœ…
```

---

## ğŸ“Š Dataset Statistics

```
RWTH-PHOENIX-Weather 2014 SI5:
â”œâ”€â”€ Total sequences: 4,657
â”œâ”€â”€ Train: 4,376 (93.9%)
â”œâ”€â”€ Dev: 106 (2.3%)
â”œâ”€â”€ Test: 175 (3.8%)
â”‚
â”œâ”€â”€ Vocabulary: ~1,066 unique signs
â”œâ”€â”€ Signers: 9 different signers
â”œâ”€â”€ Resolution: 210 x 260 pixels
â”œâ”€â”€ Frame rate: 25 FPS
â”‚
â”œâ”€â”€ Average sequence length: ~50 frames (2 seconds)
â”œâ”€â”€ Min sequence: ~10 frames
â”œâ”€â”€ Max sequence: ~200 frames
â”‚
â””â”€â”€ Storage:
    â”œâ”€â”€ Raw videos: 53GB
    â””â”€â”€ Extracted features (.npy): ~2GB (estimated)
```

---

## ğŸ¯ Target Metrics & Success Criteria

### Primary Metrics (Thesis Requirements)

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| **Word Error Rate (WER)** | <25% | TBD | â³ Week 3 |
| **Sign Error Rate (SER)** | <20% | TBD | â³ Week 3 |
| **Inference FPS** | 30+ | TBD | â³ Week 9 |
| **Model Size** | <100MB | TBD | â³ Week 7 |
| **VRAM Usage** | <8GB | âœ… 3.5GB | âœ… Pass |

### Secondary Metrics

| Metric | Target | Notes |
|--------|--------|-------|
| **End-to-end Latency** | <100ms | Camera â†’ Prediction |
| **Real-Time Factor (RTF)** | <1.0 | Processing time / video duration |
| **BLEU Score** | >0.4 | Translation quality |
| **SUS Score** | >70 | System usability |
| **Extraction FPS** | 7-10 | Offline preprocessing |

---

## âš ï¸ Risk Management

### High-Priority Risks

**Risk 1: Training Doesn't Converge**
- **Impact:** Critical - blocks all downstream work
- **Probability:** Medium (20%)
- **Mitigation:**
  - Start with proven baseline architecture
  - Use pretrained weights where possible
  - Implement extensive logging/debugging
  - Consult with supervisor early
- **Contingency:** Fall back to simpler architecture, extend timeline

**Risk 2: Can't Achieve <25% WER**
- **Impact:** High - thesis requirement
- **Probability:** Medium (30%)
- **Mitigation:**
  - Phase I baseline validates approach
  - Knowledge distillation from strong teacher
  - Extensive hyperparameter tuning
  - Consider ensemble methods
- **Contingency:** Adjust thesis to focus on efficiency/deployment contributions

**Risk 3: Real-time FPS Target (30+) Not Met**
- **Impact:** High - thesis requirement
- **Probability:** Low (15%)
- **Mitigation:**
  - TensorRT optimization (proven 2-3x speedup)
  - Model pruning/quantization
  - Efficient sliding window implementation
- **Contingency:** Relax to 20+ FPS with justification

**Risk 4: GPU Availability**
- **Impact:** High - delays all training
- **Probability:** Low (10%)
- **Mitigation:**
  - Use personal RTX 4070 laptop
  - Cloud GPU backup (Google Colab, vast.ai)
  - Optimize GPU utilization (mixed precision, batching)
- **Contingency:** Request university GPU access, rent cloud GPUs

**Risk 5: Thesis Deadline Pressure**
- **Impact:** Critical
- **Probability:** Medium (25%)
- **Mitigation:**
  - Weekly milestones with buffer time
  - Parallel work where possible
  - Start thesis writing early (Chapter I-III now)
  - Regular supervisor check-ins
- **Contingency:** Prioritize core contributions, defer nice-to-have features

### Medium-Priority Risks

**Risk 6: User Study Recruitment Challenges**
- **Impact:** Medium - affects Chapter VI
- **Probability:** High (40%)
- **Mitigation:**
  - Start recruiting early (Week 7)
  - Partner with deaf community organizations
  - Offer compensation/incentives
  - Backup: smaller sample size (n=5)
- **Contingency:** Focus on technical contributions, minimal user study

**Risk 7: Dataset Quality Issues**
- **Impact:** Medium
- **Probability:** Low (10%)
- **Mitigation:**
  - Data validation scripts
  - Manual spot-checks
  - Compare with published baselines
- **Contingency:** Data augmentation, noise handling

---

## ğŸš€ Immediate Next Actions (Start NOW)

### Monday Morning Checklist:

```bash
# 1. Archive experimental scripts
cd C:\Users\Masia\OneDrive\Desktop\sign-language-recognition
mkdir src\archive
git mv src\mediapipe_feature_extractor.py src\archive\
git mv src\extract_full_dataset.py src\archive\
git mv src\extract_full_dataset_parallel.py src\archive\
git mv src\batch_feature_extraction.py src\archive\
git mv src\gpu_yolo_extractor.py src\archive\
git add src\archive\
git commit -m "Archive experimental feature extraction scripts"
git push

# 2. Start feature extraction (train split)
# Run in screen/tmux session (will take ~18 hours)
python src\extract_features_yolov8_gpu.py --split train --batch-size 8

# 3. Monitor progress (separate terminal)
# Watch log file for errors and FPS
tail -f data\processed\logs\yolov8_extraction_*.log

# 4. Start designing BiLSTM model (parallel work)
# Create new file while extraction runs
code src\train_bilstm.py
```

### Tuesday Tasks (After Extraction Completes):

```bash
# 1. Extract dev split
python src\extract_features_yolov8_gpu.py --split dev --batch-size 8

# 2. Extract test split
python src\extract_features_yolov8_gpu.py --split test --batch-size 8

# 3. Verify extracted features
python -c "import numpy as np; f = np.load('data/processed/train/01April_2010_Thursday_heute_default-0.npy'); print(f'Shape: {f.shape}, dtype: {f.dtype}')"

# 4. Continue BiLSTM implementation
# (Should be partially complete from Monday's parallel work)
```

---

## ğŸ“š Key Research References

### Baseline Papers
- **Koller et al. (2015):** CNN-HMM baseline for RWTH-PHOENIX (~40% WER)
- **CamgÃ¶z et al. (2018):** Neural sign language translation
- **Cui et al. (2019):** Deep neural framework for continuous SLR

### Architecture References
- **Howard et al. (2019):** MobileNetV3 architecture
- **Graves et al. (2006):** Connectionist Temporal Classification (CTC)
- **Vaswani et al. (2017):** Attention mechanisms

### Knowledge Distillation
- **Hinton et al. (2015):** Distilling the knowledge in neural networks
- **Jiao et al. (2020):** TinyBERT distillation strategies

### Deployment
- **Lugaresi et al. (2019):** MediaPipe framework
- **Nikitin & Fomin (2025):** Lightweight DNN for real-time SLR

---

## ğŸ“ˆ Progress Tracking

Update this section weekly:

### Week 1 Progress (Current)
- **Date:** [Insert date]
- **Hours worked:** 20 hours
- **Tasks completed:** 3/8
- **Blockers:** None
- **Next week priority:** BiLSTM implementation

### Week 2 Progress
- **Date:** TBD
- **Hours worked:** TBD
- **Tasks completed:** TBD
- **Blockers:** TBD
- **Next week priority:** TBD

---

## ğŸ“ Thesis Writing Integration

**Parallel Writing Strategy:** Start writing while coding to avoid end-of-project rush.

### Writing Schedule:

| Week | Chapters to Draft |
|------|-------------------|
| 1-2  | Chapter I (Introduction), Chapter III (Theory) |
| 3-4  | Chapter IV (Methodology - Phase I) |
| 5-6  | Chapter IV (Methodology - Phase II) |
| 7-8  | Chapter V (Results), Chapter VII (Discussion) |
| 9-10 | Chapter VI (User Study), Chapter VIII (Conclusion) |

**Daily writing goal:** 500 words minimum

---

## âœ… Definition of Done (Per Phase)

### Phase I Complete When:
- [ ] All features extracted (4,657 sequences)
- [ ] BiLSTM model trained to convergence
- [ ] Test WER measured (35-45% range acceptable)
- [ ] Results documented in thesis
- [ ] Code committed and tagged `v0.1-baseline`
- [ ] Lessons learned documented

### Phase II Complete When:
- [ ] MobileNetV3 architecture implemented
- [ ] Knowledge distillation working
- [ ] Test WER <25% achieved âœ…
- [ ] Model size <100MB âœ…
- [ ] Ablation studies complete
- [ ] Results documented in thesis
- [ ] Code committed and tagged `v1.0-optimized`

### Phase III Complete When:
- [ ] TensorRT optimization working
- [ ] Real-time inference 30+ FPS âœ…
- [ ] Browser demo deployed
- [ ] User study complete (nâ‰¥5)
- [ ] Thesis complete and proofread
- [ ] Presentation slides ready
- [ ] Code committed and tagged `v2.0-final`

---

## ğŸ“ Getting Help

**When Stuck (>4 hours):**
1. Check CLAUDE.md for project-specific guidance
2. Consult this roadmap for context
3. Review research proposal for original plan
4. Ask supervisor for guidance
5. Post in research group chat

**Supervisor Check-ins:**
- Weekly progress meetings
- Bring: This roadmap + results summary
- Discuss: Blockers, decisions, next steps

---

## ğŸ¯ Remember

**Core Thesis Contributions:**
1. **Efficiency:** Lightweight architecture (<100MB, 8GB VRAM)
2. **Speed:** Real-time performance (30+ FPS)
3. **Accuracy:** Competitive WER (<25%)
4. **Deployment:** Practical educational application

**You've already built:** A working feature extraction pipeline! (15% of thesis done)

**Focus:** Execute the plan, one week at a time. You've got this! ğŸ’ª

---

**Last Updated:** 2025-10-14
**Next Review:** End of Week 1 (after feature extraction completes)
**Version:** 1.0
